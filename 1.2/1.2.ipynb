{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adffc0f5",
   "metadata": {},
   "source": [
    "### Base (A+B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f514900",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maze:\n",
    "    def __init__(self):\n",
    "        self.map = [[-1, -1, -1, +40],\n",
    "                    [-1, -1, -10, -10],\n",
    "                    [-1, -1, -1, -1],\n",
    "                    [+10, -2, -1, -1]]\n",
    "        self.num_rows = len(self.map)\n",
    "        self.num_cols = len(self.map[0])\n",
    "        self.start_state = (3, 2)  # row, col\n",
    "        self.terminal_states = [(0, 3), (3, 0)]\n",
    "        self.agent_pos = self.start_state\n",
    "        self.actions = {'↑': (-1, 0), '→': (0, 1), '↓': (1, 0), '←': (0, -1)}\n",
    "\n",
    "    def step(self, action):\n",
    "        move = self.actions[action]\n",
    "        row, col = self.agent_pos\n",
    "        new_row, new_col = row + move[0], col + move[1]\n",
    "        \n",
    "        # Check if new location is within map boundaries\n",
    "        if (0 <= new_row < self.num_rows) and (0 <= new_col < self.num_cols):\n",
    "            self.agent_pos = (new_row, new_col)\n",
    "            reward = self.map[new_row][new_col]\n",
    "            done = self.agent_pos in self.terminal_states\n",
    "        else:\n",
    "            # If the new location is outside the map, stay in the same spot and get the same punishment again\n",
    "            reward = self.map[row][col]\n",
    "            done = False\n",
    "        \n",
    "        return self.agent_pos, reward, done\n",
    "    \n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.maze = Maze()\n",
    "        self.policy = Policy(self.maze)\n",
    "        self.value_function = {}\n",
    "\n",
    "    def act(self, state):\n",
    "        action = self.policy.select_action(state)\n",
    "        next_state, reward, done = self.maze.step(action)\n",
    "        print(\"Agent position:\", self.maze.agent_pos)\n",
    "        print(\"Selected action:\", action)\n",
    "        return next_state, reward, done\n",
    "    \n",
    "class Policy:\n",
    "    def __init__(self, maze):\n",
    "        self.maze = maze\n",
    "        \n",
    "    def select_action(self, state):\n",
    "        possible_actions = ['↑', '→', '↓', '←']\n",
    "        return random.choice(possible_actions)\n",
    "\n",
    "\n",
    "agent = Agent()\n",
    "state = agent.maze.start_state\n",
    "\n",
    "for i in range(10):\n",
    "    action = agent.policy.select_action(state)\n",
    "    state, reward, done = agent.act(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30128a",
   "metadata": {},
   "source": [
    "## Poging tot C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed66ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value iteration converged in 16 steps.\n",
      "X\tX\tX\tT\t\n",
      "X\tX\t→\t↑\t\n",
      "X\tX\tX\tX\t\n",
      "T\t←\tX\tX\t\n",
      "\n",
      "-\t-\t-\t-\t\n",
      "-\t-\t2333300.0\t2333350.0\t\n",
      "-\t-\t-\t-\t\n",
      "-\t2333320.0\t-\t-\t\n"
     ]
    }
   ],
   "source": [
    "class Maze:\n",
    "    def __init__(self):\n",
    "        self.map = [[-1, -1, -1, 40],\n",
    "                    [-1, -1, -10, -10],\n",
    "                    [-1, -1, -1, -1],\n",
    "                    [10, -2, -1, -1]]\n",
    "        self.num_rows = len(self.map)\n",
    "        self.num_cols = len(self.map[0])\n",
    "        self.start_state = (3, 2)  # row, col\n",
    "        self.terminal_states = [(0, 3), (3, 0)]\n",
    "        self.agent_pos = self.start_state\n",
    "        self.actions = {'↑': (-1, 0), '→': (0, 1), '↓': (1, 0), '←': (0, -1)}\n",
    "\n",
    "    def step(self, state, action):\n",
    "        move = self.actions[action]\n",
    "        row, col = state\n",
    "        new_row, new_col = row + move[0], col + move[1]\n",
    "        \n",
    "        # Check if new location is within map boundaries\n",
    "        if (0 <= new_row < self.num_rows) and (0 <= new_col < self.num_cols):\n",
    "            if self.map[new_row][new_col] != -1:  # not a wall cell\n",
    "                self.agent_pos = (new_row, new_col)\n",
    "            reward = self.map[self.agent_pos[0]][self.agent_pos[1]]\n",
    "            done = self.agent_pos in self.terminal_states\n",
    "        else:\n",
    "            # If the new location is outside the map, stay in the same spot and get the same punishment again\n",
    "            reward = self.map[row][col]\n",
    "            done = False\n",
    "        \n",
    "        return self.agent_pos, reward, done\n",
    "\n",
    "\n",
    "    \n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.maze = Maze()\n",
    "        self.policy = Policy(self.maze)\n",
    "        self.value_function = {}\n",
    "        self.gamma = 1.0 # discount factor\n",
    "\n",
    "    def act(self, state):\n",
    "        action = self.policy.select_action(state)\n",
    "        next_state, reward, done = self.maze.step(action)\n",
    "        print(\"Current state:\", state)\n",
    "        print(\"Selected action:\", action)\n",
    "        print(\"Next state:\", next_state)\n",
    "        print(\"Reward:\", reward)\n",
    "        print(\"Done:\", done)\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def value_iteration(self, delta=0.01):\n",
    "        # Initialize the value of all states to 0\n",
    "        for row in range(self.maze.num_rows):\n",
    "            for col in range(self.maze.num_cols):\n",
    "                state = (row, col)\n",
    "                self.value_function[state] = 0\n",
    "\n",
    "        # Repeat until convergence\n",
    "        for i in range(100000):\n",
    "            max_change = 0\n",
    "            #print(max_change)\n",
    "\n",
    "            # Create a copy of the current value function to compare with later\n",
    "            old_value_function = self.value_function.copy()\n",
    "\n",
    "            # For each state, update its value\n",
    "            for row in range(self.maze.num_rows):\n",
    "                for col in range(self.maze.num_cols):\n",
    "                    state = (row, col)\n",
    "\n",
    "                    # Compute the optimal value for the state\n",
    "                    max_value = float('-inf')\n",
    "                    for action in self.maze.actions:\n",
    "                        next_state, reward, done = self.maze.step(state, action)\n",
    "                        value = reward + self.gamma * old_value_function[next_state]\n",
    "                        if value > max_value:\n",
    "                            max_value = value\n",
    "\n",
    "                    # Update the value of the state\n",
    "                    self.value_function[state] = max_value\n",
    "                    change = abs(max_value - old_value_function[state])\n",
    "                    if change > max_change:\n",
    "                        max_change = change\n",
    "\n",
    "            #print(max_change)\n",
    "\n",
    "            # Check for convergence\n",
    "            if max_change < delta:\n",
    "                break\n",
    "\n",
    "        print(\"Value iteration converged in\", len(self.value_function), \"steps.\")\n",
    "\n",
    "\n",
    "    def visualize(self):\n",
    "        for row in range(self.maze.num_rows):\n",
    "            for col in range(self.maze.num_cols):\n",
    "                state = (row, col)\n",
    "                if state in self.maze.terminal_states:\n",
    "                    print('T', end='\\t')\n",
    "                elif self.maze.map[row][col] == -1:\n",
    "                    print('X', end='\\t')\n",
    "                else:\n",
    "                    best_action = None\n",
    "                    best_value = float('-inf')\n",
    "                    for action in self.maze.actions:\n",
    "                        next_state, reward, done = self.maze.step(state, action) \n",
    "                        value = reward + self.gamma * self.value_function[next_state]\n",
    "                        if value > best_value:\n",
    "                            best_value = value\n",
    "                            best_action = action\n",
    "                    print(best_action, end='\\t')\n",
    "            print()\n",
    "        print()\n",
    "        for row in range(self.maze.num_rows):\n",
    "            for col in range(self.maze.num_cols):\n",
    "                state = (row, col)\n",
    "                if state in self.maze.terminal_states or self.maze.map[row][col] == -1:\n",
    "                    print('-', end='\\t')\n",
    "                else:\n",
    "                    print(round(self.value_function[state], 1), end='\\t')\n",
    "            print()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class Policy:\n",
    "    def __init__(self, maze):\n",
    "        self.maze = maze\n",
    "        \n",
    "    def select_action(self, state):\n",
    "        possible_actions = ['↑', '→', '↓', '←']\n",
    "        return random.choice(possible_actions)\n",
    "\n",
    "\n",
    "agent = Agent()\n",
    "agent.value_iteration()\n",
    "agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5988a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
